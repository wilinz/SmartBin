#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é¢„å¤„ç†æ¨¡å—
è´Ÿè´£å°†Pascal VOC XMLæ ¼å¼è½¬æ¢ä¸ºYOLOæ ¼å¼ï¼Œå¹¶è¿›è¡Œæ•°æ®é›†åˆ’åˆ†
æ”¯æŒæ•°æ®å¢å¼ºä»¥æé«˜æ¨¡å‹é²æ£’æ€§
"""

import os
import sys
import shutil
import random
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import yaml
from collections import defaultdict, Counter
import cv2
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from src.utils.config_loader import ConfigLoader
from src.data_processing.data_augmentor import DataAugmentor


class DataPreprocessor:
    """æ•°æ®é¢„å¤„ç†å™¨
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. Pascal VOC XMLæ ¼å¼è½¬æ¢ä¸ºYOLO TXTæ ¼å¼
    2. æ•°æ®é›†åˆ’åˆ†ï¼ˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼‰
    3. æ•°æ®ç»Ÿè®¡åˆ†æ
    """
    
    def __init__(self, config_path: str = "config", enable_augmentation: bool = True, augmentation_config: Optional[Dict] = None):
        """åˆå§‹åŒ–æ•°æ®é¢„å¤„ç†å™¨
        
        Args:
            config_path: é…ç½®ç›®å½•è·¯å¾„
            enable_augmentation: æ˜¯å¦å¯ç”¨æ•°æ®å¢å¼º
            augmentation_config: æ•°æ®å¢å¼ºé…ç½®
        """
        self.config_loader = ConfigLoader(config_path)
        self.model_config = self.config_loader.get_model_config()
        self.class_names = self.model_config.get('classes', {}).get('names', [])
        self.class_to_id = {name: idx for idx, name in enumerate(self.class_names)}
        
        # æ•°æ®é›†åˆ’åˆ†æ¯”ä¾‹
        self.train_ratio = 0.7
        self.val_ratio = 0.2
        self.test_ratio = 0.1
        
        # æ•°æ®å¢å¼ºé…ç½®
        self.enable_augmentation = enable_augmentation
        if self.enable_augmentation:
            self.augmentor = DataAugmentor(augmentation_config)
            print("âœ… æ•°æ®å¢å¼ºå·²å¯ç”¨")
            print(f"ğŸ“ˆ æ¯å¼ åŸå›¾å°†ç”Ÿæˆ {self.augmentor.config['augmentation_factor']} å¼ å¢å¼ºå›¾")
        else:
            self.augmentor = None
            print("âš ï¸ æ•°æ®å¢å¼ºå·²ç¦ç”¨")
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = defaultdict(int)
        
    def parse_xml_annotation(self, xml_path: str) -> List[Dict]:
        """è§£æPascal VOC XMLæ ‡æ³¨æ–‡ä»¶
        
        Args:
            xml_path: XMLæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ ‡æ³¨ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ç±»åˆ«å’Œè¾¹ç•Œæ¡†ä¿¡æ¯
        """
        tree = ET.parse(xml_path)
        root = tree.getroot()
        
        # è·å–å›¾åƒå°ºå¯¸
        size = root.find('size')
        img_width = int(size.find('width').text)
        img_height = int(size.find('height').text)
        
        annotations = []
        
        # è§£ææ‰€æœ‰å¯¹è±¡
        for obj in root.findall('object'):
            class_name = obj.find('name').text
            
            # æ£€æŸ¥ç±»åˆ«æ˜¯å¦åœ¨å®šä¹‰çš„ç±»åˆ«ä¸­
            if class_name not in self.class_to_id:
                print(f"è­¦å‘Š: æœªçŸ¥ç±»åˆ« '{class_name}' åœ¨æ–‡ä»¶ {xml_path}")
                continue
                
            class_id = self.class_to_id[class_name]
            
            # è·å–è¾¹ç•Œæ¡†åæ ‡
            bbox = obj.find('bndbox')
            xmin = int(bbox.find('xmin').text)
            ymin = int(bbox.find('ymin').text)
            xmax = int(bbox.find('xmax').text)
            ymax = int(bbox.find('ymax').text)
            
            # è½¬æ¢ä¸ºYOLOæ ¼å¼ (ç›¸å¯¹åæ ‡)
            x_center = (xmin + xmax) / 2.0 / img_width
            y_center = (ymin + ymax) / 2.0 / img_height
            width = (xmax - xmin) / img_width
            height = (ymax - ymin) / img_height
            
            annotations.append({
                'class_id': class_id,
                'class_name': class_name,
                'x_center': x_center,
                'y_center': y_center,
                'width': width,
                'height': height
            })
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.stats['total_objects'] += 1
            self.stats[f'class_{class_name}'] += 1
            
        return annotations
    
    def convert_to_yolo_format(self, data_dir: str, output_dir: str):
        """å°†Pascal VOCæ ¼å¼è½¬æ¢ä¸ºYOLOæ ¼å¼
        
        Args:
            data_dir: åŸå§‹æ•°æ®ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
        """
        data_path = Path(data_dir)
        output_path = Path(output_dir)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        output_path.mkdir(parents=True, exist_ok=True)
        images_dir = output_path / "images"
        labels_dir = output_path / "labels"
        images_dir.mkdir(exist_ok=True)
        labels_dir.mkdir(exist_ok=True)
        
        print(f"å¼€å§‹è½¬æ¢æ•°æ®æ ¼å¼...")
        print(f"æºç›®å½•: {data_path}")
        print(f"è¾“å‡ºç›®å½•: {output_path}")
        
        # éå†æ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
        converted_count = 0
        error_count = 0
        
        for class_dir in data_path.iterdir():
            if not class_dir.is_dir():
                continue
                
            class_name = class_dir.name
            print(f"å¤„ç†ç±»åˆ«: {class_name}")
            
            # æŸ¥æ‰¾æ‰€æœ‰XMLæ–‡ä»¶
            xml_files = list(class_dir.glob("*.xml"))
            
            for xml_file in xml_files:
                try:
                    # æŸ¥æ‰¾å¯¹åº”çš„å›¾åƒæ–‡ä»¶
                    img_name = xml_file.stem + ".jpg"
                    img_file = class_dir / img_name
                    
                    if not img_file.exists():
                        print(f"è­¦å‘Š: æ‰¾ä¸åˆ°å¯¹åº”çš„å›¾åƒæ–‡ä»¶: {img_file}")
                        continue
                    
                    # è§£æXMLæ ‡æ³¨
                    annotations = self.parse_xml_annotation(str(xml_file))
                    
                    if not annotations:
                        print(f"è­¦å‘Š: XMLæ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆæ ‡æ³¨: {xml_file}")
                        continue
                    
                    # è¯»å–å›¾åƒ
                    image = cv2.imread(str(img_file))
                    if image is None:
                        print(f"è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {img_file}")
                        continue
                    
                    # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åï¼ˆåŒ…å«ç±»åˆ«ä¿¡æ¯ï¼‰
                    base_name = f"{class_name}_{xml_file.stem}"
                    
                    # å¦‚æœå¯ç”¨æ•°æ®å¢å¼ºï¼Œç”Ÿæˆå¢å¼ºæ•°æ®
                    if self.enable_augmentation and self.augmentor:
                        try:
                            # åº”ç”¨æ•°æ®å¢å¼º
                            augmented_pairs = self.augmentor.augment_image_with_annotations(image, annotations)
                            
                            # ä¿å­˜æ‰€æœ‰å¢å¼ºåçš„å›¾åƒå’Œæ ‡æ³¨
                            for idx, (aug_image, aug_annotations) in enumerate(augmented_pairs):
                                if idx == 0:
                                    # åŸå§‹å›¾åƒ
                                    unique_name = base_name
                                else:
                                    # å¢å¼ºå›¾åƒ
                                    unique_name = f"{base_name}_aug_{idx}"
                                
                                # ä¿å­˜å›¾åƒ
                                dest_img = images_dir / f"{unique_name}.jpg"
                                cv2.imwrite(str(dest_img), aug_image)
                                
                                # ä¿å­˜æ ‡æ³¨
                                label_file = labels_dir / f"{unique_name}.txt"
                                with open(label_file, 'w') as f:
                                    for ann in aug_annotations:
                                        f.write(f"{ann['class_id']} {ann['x_center']:.6f} "
                                               f"{ann['y_center']:.6f} {ann['width']:.6f} "
                                               f"{ann['height']:.6f}\n")
                                
                                converted_count += 1
                        
                        except Exception as e:
                            print(f"æ•°æ®å¢å¼ºå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ® {xml_file}: {str(e)}")
                            # é™çº§å¤„ç†ï¼šåªä¿å­˜åŸå§‹å›¾åƒ
                            dest_img = images_dir / f"{base_name}.jpg"
                            cv2.imwrite(str(dest_img), image)
                            
                            label_file = labels_dir / f"{base_name}.txt"
                            with open(label_file, 'w') as f:
                                for ann in annotations:
                                    f.write(f"{ann['class_id']} {ann['x_center']:.6f} "
                                           f"{ann['y_center']:.6f} {ann['width']:.6f} "
                                           f"{ann['height']:.6f}\n")
                            
                            converted_count += 1
                    else:
                        # ä¸ä½¿ç”¨æ•°æ®å¢å¼ºï¼Œç›´æ¥ä¿å­˜åŸå§‹å›¾åƒ
                        dest_img = images_dir / f"{base_name}.jpg"
                        cv2.imwrite(str(dest_img), image)
                        
                        label_file = labels_dir / f"{base_name}.txt"
                        with open(label_file, 'w') as f:
                            for ann in annotations:
                                f.write(f"{ann['class_id']} {ann['x_center']:.6f} "
                                       f"{ann['y_center']:.6f} {ann['width']:.6f} "
                                       f"{ann['height']:.6f}\n")
                        
                        converted_count += 1
                    
                except Exception as e:
                    print(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™ {xml_file}: {str(e)}")
                    error_count += 1
                    continue
        
        print(f"\nè½¬æ¢å®Œæˆ!")
        print(f"æˆåŠŸè½¬æ¢: {converted_count} ä¸ªæ–‡ä»¶")
        print(f"é”™è¯¯æ•°é‡: {error_count} ä¸ªæ–‡ä»¶")
        
        if self.enable_augmentation:
            original_count = len([f for f in os.listdir(images_dir) if not '_aug_' in f])
            augmented_count = converted_count - original_count
            print(f"åŸå§‹å›¾åƒ: {original_count} å¼ ")
            print(f"å¢å¼ºå›¾åƒ: {augmented_count} å¼ ")
            print(f"æ•°æ®å¢å¼ºå€æ•°: {converted_count/original_count:.1f}x" if original_count > 0 else "æ•°æ®å¢å¼ºå€æ•°: 0x")
        
        self.stats['converted_files'] = converted_count
        self.stats['error_files'] = error_count
    
    def split_dataset(self, dataset_dir: str, output_dir: str):
        """åˆ’åˆ†æ•°æ®é›†ä¸ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
        
        Args:
            dataset_dir: è½¬æ¢åçš„æ•°æ®é›†ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
        """
        dataset_path = Path(dataset_dir)
        output_path = Path(output_dir)
        
        images_dir = dataset_path / "images"
        labels_dir = dataset_path / "labels"
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_files = list(images_dir.glob("*.jpg"))
        random.shuffle(image_files)
        
        total_files = len(image_files)
        train_count = int(total_files * self.train_ratio)
        val_count = int(total_files * self.val_ratio)
        
        # åˆ’åˆ†æ•°æ®é›†
        train_files = image_files[:train_count]
        val_files = image_files[train_count:train_count + val_count]
        test_files = image_files[train_count + val_count:]
        
        print(f"\næ•°æ®é›†åˆ’åˆ†:")
        print(f"æ€»æ–‡ä»¶æ•°: {total_files}")
        print(f"è®­ç»ƒé›†: {len(train_files)} ({len(train_files)/total_files*100:.1f}%)")
        print(f"éªŒè¯é›†: {len(val_files)} ({len(val_files)/total_files*100:.1f}%)")
        print(f"æµ‹è¯•é›†: {len(test_files)} ({len(test_files)/total_files*100:.1f}%)")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        for split in ['train', 'val', 'test']:
            (output_path / split / 'images').mkdir(parents=True, exist_ok=True)
            (output_path / split / 'labels').mkdir(parents=True, exist_ok=True)
        
        # å¤åˆ¶æ–‡ä»¶åˆ°å¯¹åº”ç›®å½•
        def copy_split_files(files: List[Path], split_name: str):
            split_dir = output_path / split_name
            for img_file in files:
                # å¤åˆ¶å›¾åƒæ–‡ä»¶
                dest_img = split_dir / 'images' / img_file.name
                shutil.copy2(img_file, dest_img)
                
                # å¤åˆ¶æ ‡ç­¾æ–‡ä»¶
                label_file = labels_dir / (img_file.stem + '.txt')
                if label_file.exists():
                    dest_label = split_dir / 'labels' / (img_file.stem + '.txt')
                    shutil.copy2(label_file, dest_label)
        
        copy_split_files(train_files, 'train')
        copy_split_files(val_files, 'val')
        copy_split_files(test_files, 'test')
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.stats['train_files'] = len(train_files)
        self.stats['val_files'] = len(val_files)
        self.stats['test_files'] = len(test_files)
        
        # åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶
        self.create_dataset_yaml(output_path)
    
    def create_dataset_yaml(self, output_dir: Path):
        """åˆ›å»ºYOLOæ•°æ®é›†é…ç½®æ–‡ä»¶
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        dataset_config = {
            'path': str(output_dir.absolute()),
            'train': 'train/images',
            'val': 'val/images',
            'test': 'test/images',
            'nc': len(self.class_names),
            'names': self.class_names
        }
        
        yaml_file = output_dir / 'dataset.yaml'
        with open(yaml_file, 'w', encoding='utf-8') as f:
            yaml.dump(dataset_config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"æ•°æ®é›†é…ç½®æ–‡ä»¶å·²åˆ›å»º: {yaml_file}")
    
    def analyze_dataset(self, dataset_dir: str) -> Dict:
        """åˆ†ææ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            dataset_dir: æ•°æ®é›†ç›®å½•
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        dataset_path = Path(dataset_dir)
        
        # ç»Ÿè®¡å„splitçš„ä¿¡æ¯
        analysis = {
            'total_images': 0,
            'total_objects': 0,
            'class_distribution': Counter(),
            'splits': {}
        }
        
        for split in ['train', 'val', 'test']:
            split_dir = dataset_path / split
            if not split_dir.exists():
                continue
                
            images_dir = split_dir / 'images'
            labels_dir = split_dir / 'labels'
            
            image_files = list(images_dir.glob('*.jpg'))
            split_info = {
                'image_count': len(image_files),
                'object_count': 0,
                'class_distribution': Counter()
            }
            
            # ç»Ÿè®¡æ ‡ç­¾ä¿¡æ¯
            for img_file in image_files:
                label_file = labels_dir / (img_file.stem + '.txt')
                if label_file.exists():
                    with open(label_file, 'r') as f:
                        for line in f:
                            parts = line.strip().split()
                            if len(parts) >= 5:
                                class_id = int(parts[0])
                                class_name = self.class_names[class_id]
                                split_info['class_distribution'][class_name] += 1
                                split_info['object_count'] += 1
            
            analysis['splits'][split] = split_info
            analysis['total_images'] += split_info['image_count']
            analysis['total_objects'] += split_info['object_count']
            analysis['class_distribution'].update(split_info['class_distribution'])
        
        return analysis
    
    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n=== æ•°æ®é¢„å¤„ç†ç»Ÿè®¡ä¿¡æ¯ ===")
        print(f"è½¬æ¢æ–‡ä»¶æ•°: {self.stats.get('converted_files', 0)}")
        print(f"é”™è¯¯æ–‡ä»¶æ•°: {self.stats.get('error_files', 0)}")
        print(f"æ€»å¯¹è±¡æ•°: {self.stats.get('total_objects', 0)}")
        
        print("\nç±»åˆ«åˆ†å¸ƒ:")
        for class_name in self.class_names:
            count = self.stats.get(f'class_{class_name}', 0)
            print(f"  {class_name}: {count}")
        
        if 'train_files' in self.stats:
            print(f"\næ•°æ®é›†åˆ’åˆ†:")
            print(f"  è®­ç»ƒé›†: {self.stats['train_files']}")
            print(f"  éªŒè¯é›†: {self.stats['val_files']}")
            print(f"  æµ‹è¯•é›†: {self.stats['test_files']}")
    
    def process_data(self, source_dir: str, work_dir: str = "datasets"):
        """å®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹
        
        Args:
            source_dir: æºæ•°æ®ç›®å½•
            work_dir: å·¥ä½œç›®å½•
        """
        work_path = Path(work_dir)
        work_path.mkdir(exist_ok=True)
        
        print("å¼€å§‹æ•°æ®é¢„å¤„ç†æµç¨‹...")
        
        # æ­¥éª¤1: æ ¼å¼è½¬æ¢
        converted_dir = work_path / "converted"
        self.convert_to_yolo_format(source_dir, str(converted_dir))
        
        # æ­¥éª¤2: æ•°æ®é›†åˆ’åˆ†
        final_dir = work_path / "yolo_dataset"
        self.split_dataset(str(converted_dir), str(final_dir))
        
        # æ­¥éª¤3: æ•°æ®åˆ†æ
        analysis = self.analyze_dataset(str(final_dir))
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        self.print_statistics()
        
        print(f"\næ•°æ®é¢„å¤„ç†å®Œæˆ!")
        print(f"æœ€ç»ˆæ•°æ®é›†ä½ç½®: {final_dir.absolute()}")
        print(f"æ•°æ®é›†é…ç½®æ–‡ä»¶: {final_dir / 'dataset.yaml'}")
        
        return str(final_dir)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    preprocessor = DataPreprocessor()
    
    # å¤„ç†æ•°æ®
    source_data_dir = "data"  # åŸå§‹æ•°æ®ç›®å½•
    final_dataset_dir = preprocessor.process_data(source_data_dir)
    
    print(f"å¤„ç†å®Œæˆ! æ•°æ®é›†ä¿å­˜åœ¨: {final_dataset_dir}") 